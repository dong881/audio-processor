import os
import sys
import tempfile
import shutil
import subprocess
import logging
import uuid
import threading
import time
from datetime import datetime
from typing import Dict, List, Tuple, Any, Optional
from concurrent.futures import ThreadPoolExecutor
from pathlib import Path

# èªéŸ³è™•ç†ç›¸é—œ
import whisper
from pyannote.audio import Pipeline
import numpy as np
import soundfile as sf
import librosa

# å°å…¥å°ˆç”¨æ¨¡çµ„
from .google_service import GoogleService
from note_handler import NoteHandler

class AudioProcessor:
    """
    éŸ³é »è™•ç†æ ¸å¿ƒé¡åˆ¥ï¼Œè² è²¬éŸ³é »è½‰æ›ã€è™•ç†ã€è­˜åˆ¥åŠå·¥ä½œæµç¨‹å”èª¿
    æ¡ç”¨å–®ä¾‹æ¨¡å¼ç¢ºä¿å…¨æ‡‰ç”¨çµ±ä¸€è™•ç†ç‹€æ…‹
    """
    _instance = None
    
    @classmethod
    def get_instance(cls):
        """å–®ä¾‹æ¨¡å¼ç²å–å¯¦ä¾‹"""
        if cls._instance is None:
            # ç¢ºä¿ç›¸ä¾çš„é¡åˆ¥å­˜åœ¨
            from notion_formatter import NotionFormatter
            note_handler = NoteHandler(NotionFormatter())
            cls._instance = AudioProcessor(note_handler=note_handler)
        return cls._instance
    
    def __init__(self, note_handler, max_workers=3):
        """
        åˆå§‹åŒ–è™•ç†å™¨
        
        Args:
            note_handler: è™•ç†æ‘˜è¦ã€ç­†è¨˜å’Œ Notion æ•´åˆçš„è™•ç†å™¨
            max_workers: åŒæ™‚è™•ç†çš„æœ€å¤§å·¥ä½œæ•¸
        """
        # å­˜å„²å–®ä¾‹å¯¦ä¾‹
        AudioProcessor._instance = self
        
        # æ¨¡å‹å¯¦ä¾‹
        self.whisper_model = None
        self.diarization_pipeline = None
        
        # å·¥ä½œç®¡ç†ç›¸é—œ
        self.max_workers = max_workers
        self.executor = ThreadPoolExecutor(max_workers=max_workers)
        self.jobs = {}
        self.jobs_lock = threading.Lock()
        
        # ä¾è³´çš„æœå‹™
        self.note_handler = note_handler
        self.google_service = GoogleService()
        
        # å·¥ä½œç‹€æ…‹å¸¸é‡
        self.JOB_STATUS = {
            'PENDING': 'pending',      # ç­‰å¾…è™•ç†
            'PROCESSING': 'processing', # è™•ç†ä¸­
            'COMPLETED': 'completed',   # è™•ç†å®Œæˆ
            'FAILED': 'failed'         # è™•ç†å¤±æ•—
        }
        
    def load_models(self):
        """è¼‰å…¥ AI æ¨¡å‹ï¼ŒåŒ…æ‹¬èªéŸ³è½‰æ–‡å­—å’Œèªªè©±äººåˆ†é›¢"""
        try:
            logging.info("ğŸ”„ è¼‰å…¥èªéŸ³è™•ç†æ¨¡å‹...")
            
            # è¼‰å…¥ Whisper æ¨¡å‹
            if self.whisper_model is None:
                model_size = os.getenv("WHISPER_MODEL_SIZE", "medium")
                logging.info(f"- è¼‰å…¥ Whisper {model_size} æ¨¡å‹...")
                self.whisper_model = whisper.load_model(model_size)
                logging.info("âœ… Whisper æ¨¡å‹è¼‰å…¥å®Œæˆ")
            
            # è¼‰å…¥èªªè©±äººåˆ†é›¢æ¨¡å‹
            if self.diarization_pipeline is None:
                hf_token = os.getenv("HF_TOKEN")
                if not hf_token:
                    raise ValueError("æœªè¨­ç½® HF_TOKEN ç’°å¢ƒè®Šæ•¸ï¼Œç„¡æ³•è¼‰å…¥èªªè©±äººåˆ†é›¢æ¨¡å‹")
                
                # æ·»åŠ é‡è©¦é‚è¼¯ï¼Œé¿å…ç¶²è·¯å•é¡Œ
                max_retries = 3
                for attempt in range(max_retries):
                    try:
                        logging.info(f"- è¼‰å…¥èªªè©±äººåˆ†é›¢æ¨¡å‹ (å˜—è©¦ {attempt + 1}/{max_retries})...")
                        self.diarization_pipeline = Pipeline.from_pretrained(
                            "pyannote/speaker-diarization-3.1",
                            use_auth_token=hf_token
                        )
                        logging.info("âœ… èªªè©±äººåˆ†é›¢æ¨¡å‹è¼‰å…¥å®Œæˆ")
                        break
                    except Exception as e:
                        if attempt < max_retries - 1:
                            logging.warning(f"âš ï¸ è¼‰å…¥èªªè©±äººåˆ†é›¢æ¨¡å‹å¤±æ•—ï¼Œå°‡é‡è©¦: {str(e)}")
                            time.sleep(2)  # ç­‰å¾…å¾Œé‡è©¦
                        else:
                            logging.error(f"âŒ è¼‰å…¥èªªè©±äººåˆ†é›¢æ¨¡å‹å¤±æ•—: {str(e)}")
                            raise
                            
            logging.info("âœ… æ‰€æœ‰æ¨¡å‹è¼‰å…¥å®Œæˆ")
            return True
            
        except Exception as e:
            logging.error(f"âŒ è¼‰å…¥æ¨¡å‹å¤±æ•—: {str(e)}", exc_info=True)
            raise
    
    def convert_to_wav(self, input_path: str) -> str:
        """
        å°‡éŸ³æª”è½‰æ›ç‚º WAV æ ¼å¼ (16kHz, å–®è²é“)
        
        Args:
            input_path: è¼¸å…¥æª”æ¡ˆè·¯å¾‘
            
        Returns:
            è½‰æ›å¾Œ WAV æª”æ¡ˆçš„è·¯å¾‘
        """
        # å¦‚æœå·²ç¶“æ˜¯ WAV æª”æ¡ˆï¼Œç›´æ¥è¿”å›
        if input_path.lower().endswith(".wav"):
            return input_path
            
        logging.info(f"ğŸ”„ è½‰æ›éŸ³é »æ ¼å¼: {os.path.basename(input_path)}")
        
        # å‰µå»ºè‡¨æ™‚ç›®éŒ„
        output_dir = tempfile.mkdtemp()
        output_path = os.path.join(output_dir, "converted.wav")
        
        try:
            # ä½¿ç”¨ FFmpeg è½‰æ›
            cmd = [
                "ffmpeg",
                "-y",                   # è¦†è“‹è¼¸å‡ºæª”æ¡ˆ
                "-i", input_path,       # è¼¸å…¥æª”æ¡ˆ
                "-ar", "16000",         # å–æ¨£ç‡ï¼š16kHz
                "-ac", "1",             # è²é“æ•¸ï¼š1 (å–®è²é“)
                "-c:a", "pcm_s16le",    # ç·¨ç¢¼ï¼š16-bit PCM
                output_path             # è¼¸å‡ºæª”æ¡ˆ
            ]
            
            result = subprocess.run(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True
            )
            
            if result.returncode != 0:
                logging.error(f"âŒ FFmpeg è½‰æ›å¤±æ•—: {result.stderr}")
                raise RuntimeError(f"FFmpeg è½‰æ›å¤±æ•—: {result.stderr}")
            
            logging.info("âœ… æ ¼å¼è½‰æ›å®Œæˆ")
            return output_path
            
        except Exception as e:
            logging.error(f"âŒ æª”æ¡ˆè½‰æ›å¤±æ•—: {str(e)}", exc_info=True)
            # æ¸…ç†è‡¨æ™‚ç›®éŒ„
            if os.path.exists(output_dir):
                shutil.rmtree(output_dir)
            raise
    
    def remove_silence(self, audio_path: str) -> str:
        """
        ç§»é™¤éŸ³æª”ä¸­çš„éœéŸ³éƒ¨åˆ†ï¼Œå„ªåŒ–è™•ç†æ•ˆç‡
        
        Args:
            audio_path: è¼¸å…¥éŸ³é »æª”æ¡ˆè·¯å¾‘
            
        Returns:
            è™•ç†å¾Œæª”æ¡ˆè·¯å¾‘
        """
        logging.info(f"ğŸ”„ ç§»é™¤éŸ³æª”ä¸­çš„éœéŸ³: {os.path.basename(audio_path)}")
        
        try:
            # è¼‰å…¥éŸ³é »
            y, sr = librosa.load(audio_path, sr=None)
            
            # æª¢æ¸¬ééœéŸ³éƒ¨åˆ†
            non_silent_intervals = librosa.effects.split(
                y, top_db=30, frame_length=2048, hop_length=512
            )
            
            if len(non_silent_intervals) == 0:
                logging.warning("âš ï¸ æ‰¾ä¸åˆ°ééœéŸ³éƒ¨åˆ†ï¼Œè¿”å›åŸå§‹æª”æ¡ˆ")
                return audio_path
            
            # åˆä½µééœéŸ³éƒ¨åˆ†
            y_trimmed = np.concatenate([y[start:end] for start, end in non_silent_intervals])
            
            # ç”Ÿæˆè¼¸å‡ºè·¯å¾‘
            output_dir = os.path.dirname(audio_path)
            output_path = os.path.join(output_dir, "trimmed.wav")
            
            # å„²å­˜è™•ç†å¾Œçš„æª”æ¡ˆ
            sf.write(output_path, y_trimmed, sr)
            
            # è¨ˆç®—ç¸®æ¸›æ¯”ä¾‹
            reduction = (1 - len(y_trimmed) / len(y)) * 100
            logging.info(f"âœ… éœéŸ³ç§»é™¤å®Œæˆï¼Œæª”æ¡ˆç¸®æ¸› {reduction:.1f}%")
            
            return output_path
            
        except Exception as e:
            logging.error(f"âŒ ç§»é™¤éœéŸ³å¤±æ•—: {str(e)}", exc_info=True)
            return audio_path  # éŒ¯èª¤æ™‚è¿”å›åŸå§‹æª”æ¡ˆ
    
    def process_audio(self, audio_path: str) -> Tuple[str, List[Dict[str, Any]], List[str]]:
        """
        è™•ç†éŸ³é »æª”æ¡ˆï¼ŒåŸ·è¡Œè½‰éŒ„èˆ‡èªªè©±äººåˆ†é›¢
        
        Args:
            audio_path: éŸ³é »æª”æ¡ˆè·¯å¾‘
            
        Returns:
            Tuple[str, List[Dict], List[str]]: åŒ…å«å®Œæ•´æ–‡æœ¬ã€åˆ†æ®µå…§å®¹èˆ‡èªªè©±äººåˆ—è¡¨çš„å…ƒçµ„
        """
        logging.info(f"ğŸ”„ è™•ç†éŸ³é »æª”æ¡ˆ: {os.path.basename(audio_path)}")
        
        # ç¢ºä¿æ¨¡å‹å·²è¼‰å…¥
        if not self.whisper_model or not self.diarization_pipeline:
            self.load_models()
        
        # æª¢æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(audio_path):
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°éŸ³é »æª”æ¡ˆ: {audio_path}")
            
        try:
            # é è™•ç†éŸ³é »
            if not audio_path.lower().endswith('.wav'):
                wav_path = self.convert_to_wav(audio_path)
                # è™•ç†å®Œæˆå¾Œç§»é™¤åŸå§‹æª”æ¡ˆä»¥ç¯€çœç©ºé–“
                if wav_path != audio_path and os.path.exists(audio_path):
                    os.unlink(audio_path)
                audio_path = wav_path
            
            # ç§»é™¤éœéŸ³ï¼ˆå¯é¸ï¼‰
            if os.getenv("REMOVE_SILENCE", "true").lower() == "true":
                audio_path = self.remove_silence(audio_path)
            
            # èªéŸ³è½‰æ–‡å­—
            logging.info("- åŸ·è¡ŒèªéŸ³è½‰æ–‡å­—...")
            transcription = self.whisper_model.transcribe(
                audio_path, 
                language=os.getenv("WHISPER_LANGUAGE", None),
                verbose=False
            )
            
            # èªªè©±äººåˆ†é›¢
            logging.info("- åŸ·è¡Œèªªè©±äººåˆ†é›¢...")
            diarization = self.diarization_pipeline(audio_path)
            
            # æ•´åˆçµæœ
            segments = []
            full_transcript = ""
            speaker_set = set()
            
            # è™•ç†æ¯å€‹æ®µè½
            for i, segment in enumerate(transcription["segments"]):
                segment_start = segment["start"]
                segment_end = segment["end"]
                text = segment["text"].strip()
                
                # æ‰¾å‡ºæ­¤æ®µè½çš„ä¸»è¦èªªè©±äºº
                speakers = {}
                for turn, _, speaker in diarization.itertracks(yield_label=True):
                    # è¨ˆç®—é‡ç–Šæ™‚é–“
                    overlap_start = max(segment_start, turn.start)
                    overlap_end = min(segment_end, turn.end)
                    
                    if overlap_end > overlap_start:  # æœ‰é‡ç–Š
                        overlap_duration = overlap_end - overlap_start
                        speakers[speaker] = speakers.get(speaker, 0) + overlap_duration
                
                # æ‰¾å‡ºä¸»è¦èªªè©±äºº
                main_speaker = max(speakers.items(), key=lambda x: x[1])[0] if speakers else "æœªçŸ¥"
                speaker_set.add(main_speaker)
                
                # æ·»åŠ åˆ°çµæœ
                segments.append({
                    "speaker": main_speaker,
                    "start": segment_start,
                    "end": segment_end,
                    "text": text,
                    "timestamp": self.format_timestamp(segment_start)
                })
                
                full_transcript += f"[{main_speaker}]: {text}\n"
            
            logging.info(f"âœ… éŸ³é »è™•ç†å®Œæˆ: {len(segments)} å€‹æ®µè½ï¼Œ{len(speaker_set)} ä½èªªè©±äºº")
            return full_transcript, segments, list(speaker_set)
            
        except Exception as e:
            logging.error(f"âŒ éŸ³é »è™•ç†å¤±æ•—: {str(e)}", exc_info=True)
            raise
    
    def process_file_async(self, file_id: str, attachment_file_id: Optional[str] = None) -> str:
        """
        éåŒæ­¥è™•ç†æª”æ¡ˆï¼Œè¿”å›å·¥ä½œ ID
        
        Args:
            file_id: Google Drive æª”æ¡ˆ ID
            attachment_file_id: å¯é¸çš„é™„ä»¶æª”æ¡ˆ ID (å¦‚ PDF)
            
        Returns:
            å·¥ä½œ ID
        """
        # ç”Ÿæˆå”¯ä¸€å·¥ä½œ ID
        job_id = str(uuid.uuid4())
        
        # åˆå§‹åŒ–å·¥ä½œè³‡è¨Š
        with self.jobs_lock:
            self.jobs[job_id] = {
                'id': job_id,
                'file_id': file_id,
                'attachment_file_id': attachment_file_id,
                'status': self.JOB_STATUS['PENDING'],
                'progress': 0,
                'created_at': datetime.now().isoformat(),
                'updated_at': datetime.now().isoformat(),
                'result': None,
                'error': None,
                'message': 'å·¥ä½œå·²åŠ å…¥éšŠåˆ—ï¼Œç­‰å¾…è™•ç†'
            }
        
        # æäº¤å·¥ä½œåˆ°åŸ·è¡Œç·’æ± 
        self.executor.submit(
            self._process_file_job, job_id, file_id, attachment_file_id
        )
        
        return job_id
    
    def _process_file_job(self, job_id: str, file_id: str, attachment_file_id: Optional[str] = None):
        """
        è™•ç†æª”æ¡ˆçš„èƒŒæ™¯å·¥ä½œ
        
        Args:
            job_id: å·¥ä½œID
            file_id: Google Drive æª”æ¡ˆID
            attachment_file_id: é™„ä»¶æª”æ¡ˆID (å¦‚ PDF)
        """
        audio_temp_dir = None
        attachment_temp_dir = None
        attachment_text = None
        
        # æ›´æ–°å·¥ä½œç‹€æ…‹
        self._update_job_status(job_id, status=self.JOB_STATUS['PROCESSING'], 
                               progress=5, message="é–‹å§‹è™•ç†æª”æ¡ˆ")
        
        try:
            logging.info(f"[Job {job_id}] é–‹å§‹è™•ç†æª”æ¡ˆï¼ŒID: {file_id}")
            
            # ç²å–æª”æ¡ˆè³‡è¨Š
            try:
                file_details = self.google_service.get_file_details(file_id)
                file_name = file_details.get('name', f"file_{file_id}")
                
                self._update_job_status(job_id, progress=10, 
                                       message=f"è™•ç†æª”æ¡ˆ: {file_name}")
            except Exception as e:
                logging.error(f"[Job {job_id}] âŒ ç²å–æª”æ¡ˆè³‡è¨Šå¤±æ•—: {str(e)}")
                self._update_job_status(job_id, message=f"ç²å–æª”æ¡ˆè³‡è¨Šå¤±æ•—: {str(e)}")
                file_name = f"file_{file_id}"
            
            # è™•