import os
import sys
import tempfile
import shutil
import subprocess
import io
import json
from datetime import datetime
from typing import Dict, List, Tuple, Any, Optional

# Flask ç›¸é—œ
from flask import Flask, request, jsonify
import requests

# Google API ç›¸é—œ
from google.oauth2.credentials import Credentials
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload

# èªéŸ³è™•ç†ç›¸é—œ
import whisper
from pyannote.audio import Pipeline

# LLM API ç›¸é—œ
import google.generativeai as genai

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
from dotenv import load_dotenv
load_dotenv()

app = Flask(__name__)

class AudioProcessor:
    def __init__(self):
        self.whisper_model = None
        self.diarization_pipeline = None
        self.drive_service = None
        self.init_services()

    def init_services(self):
        """åˆå§‹åŒ–æ‰€æœ‰éœ€è¦çš„æœå‹™"""
        print("ğŸ”„ åˆå§‹åŒ–æœå‹™ä¸­...")
        
        # åˆå§‹åŒ– Google Drive API
        if os.getenv("USE_SERVICE_ACCOUNT") == "true":
            # ä½¿ç”¨æœå‹™å¸³è™Ÿ
            credentials = service_account.Credentials.from_service_account_file(
                os.getenv("GOOGLE_SA_JSON_PATH"),
                scopes=['https://www.googleapis.com/auth/drive.readonly']
            )
        else:
            # ä½¿ç”¨ OAuth æ†‘è­‰
            credentials = Credentials.from_authorized_user_file(
                os.getenv("GOOGLE_CREDS_JSON_PATH"),
                scopes=['https://www.googleapis.com/auth/drive.readonly']
            )
        
        self.drive_service = build('drive', 'v3', credentials=credentials)
        
        # åˆå§‹åŒ– Google Gemini API
        genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
        
        print("âœ… æœå‹™åˆå§‹åŒ–å®Œæˆ")

    def load_models(self):
        """æ‡¶åŠ è¼‰ AI æ¨¡å‹ï¼Œç¯€çœè¨˜æ†¶é«”"""
        print("ğŸ”„ è¼‰å…¥AIæ¨¡å‹...")
        
        # è¼‰å…¥ Whisper æ¨¡å‹ (å¦‚æœå°šæœªè¼‰å…¥)
        if self.whisper_model is None:
            print("- è¼‰å…¥ Whisper æ¨¡å‹...")
            self.whisper_model = whisper.load_model("base")
            print("- Whisper æ¨¡å‹è¼‰å…¥å®Œæˆ")
        
        # è¼‰å…¥ Pyannote æ¨¡å‹ (å¦‚æœå°šæœªè¼‰å…¥)
        if self.diarization_pipeline is None:
            print("- è¼‰å…¥ Pyannote èªªè©±äººåˆ†é›¢æ¨¡å‹...")
            self.diarization_pipeline = Pipeline.from_pretrained(
                "pyannote/speaker-diarization-3.1",
                use_auth_token=os.getenv("HF_TOKEN")
            )
            print("- Pyannote æ¨¡å‹è¼‰å…¥å®Œæˆ")
            
        print("âœ… æ‰€æœ‰AIæ¨¡å‹è¼‰å…¥å®Œæˆ")

    def download_from_drive(self, file_id: str) -> str:
        """å¾ Google Drive ä¸‹è¼‰æª”æ¡ˆåˆ°è‡¨æ™‚ç›®éŒ„"""
        print(f"ğŸ”„ å¾ Google Drive ä¸‹è¼‰æª”æ¡ˆ (ID: {file_id})...")
        
        # å»ºç«‹è‡¨æ™‚ç›®éŒ„
        temp_dir = tempfile.mkdtemp()
        
        try:
            # å–å¾—æª”æ¡ˆè³‡è¨Š
            file_meta = self.drive_service.files().get(
                fileId=file_id, fields="name,mimeType"
            ).execute()
            
            filename = file_meta.get('name', f'audio_{file_id}')
            mime_type = file_meta.get('mimeType', '')
            
            print(f"- æª”æ¡ˆåç¨±: {filename}")
            print(f"- MIMEé¡å‹: {mime_type}")
            
            # å»ºç«‹æœ¬åœ°æª”æ¡ˆè·¯å¾‘
            local_path = os.path.join(temp_dir, filename)
            
            # ä¸‹è¼‰æª”æ¡ˆ
            request = self.drive_service.files().get_media(fileId=file_id)
            with io.FileIO(local_path, 'wb') as fh:
                downloader = MediaIoBaseDownload(fh, request)
                done = False
                while not done:
                    status, done = downloader.next_chunk()
                    print(f"- ä¸‹è¼‰é€²åº¦: {int(status.progress() * 100)}%")
            
            print(f"âœ… æª”æ¡ˆä¸‹è¼‰å®Œæˆ: {local_path}")
            return local_path
            
        except Exception as e:
            print(f"âŒ æª”æ¡ˆä¸‹è¼‰å¤±æ•—: {str(e)}")
            shutil.rmtree(temp_dir)
            raise

    def convert_to_wav(self, input_path: str) -> str:
        """å°‡éŸ³æª”è½‰æ›ç‚º WAV æ ¼å¼ (16kHz, å–®è²é“)"""
        print(f"ğŸ”„ è½‰æ›æª”æ¡ˆæ ¼å¼: {os.path.basename(input_path)} -> WAV")
        
        # åœ¨ç›¸åŒç›®éŒ„ä¸­å»ºç«‹æš«å­˜ WAV æª”æ¡ˆ
        dir_path = os.path.dirname(input_path)
        temp_wav = tempfile.NamedTemporaryFile(
            suffix=".wav", delete=False, dir=dir_path
        )
        temp_wav.close()
        
        # ä½¿ç”¨ FFmpeg é€²è¡Œè½‰æ›
        cmd = [
            'ffmpeg', '-y',
            '-i', input_path,
            '-acodec', 'pcm_s16le',  # 16-bit PCM
            '-ar', '16000',          # 16kHz å–æ¨£ç‡
            '-ac', '1',              # å–®è²é“
            temp_wav.name
        ]
        
        try:
            result = subprocess.run(
                cmd, 
                check=True, 
                stdout=subprocess.PIPE, 
                stderr=subprocess.PIPE
            )
            print(f"âœ… è½‰æ›æˆåŠŸ: {temp_wav.name}")
            return temp_wav.name
        except subprocess.CalledProcessError as e:
            print(f"âŒ è½‰æ›å¤±æ•—: {str(e)}")
            print(f"FFmpeg stderr: {e.stderr.decode('utf-8', errors='replace')}")
            os.remove(temp_wav.name)
            raise RuntimeError("éŸ³æª”è½‰æ›å¤±æ•—")

    def process_audio(self, audio_path: str) -> Tuple[str, List[Dict[str, Any]]]:
        """è™•ç†éŸ³æª”ï¼šè½‰æ–‡å­—ä¸¦é€²è¡Œèªªè©±äººåˆ†é›¢"""
        print(f"ğŸ”„ è™•ç†éŸ³æª”: {os.path.basename(audio_path)}")
        
        # ç¢ºä¿æ¨¡å‹å·²è¼‰å…¥
        self.load_models()
        
        # å¦‚æœæª”æ¡ˆé WAV æ ¼å¼ï¼Œå…ˆè½‰æ›
        if not audio_path.lower().endswith('.wav'):
            wav_path = self.convert_to_wav(audio_path)
            # å¯é¸ï¼šç§»é™¤åŸå§‹æª”æ¡ˆä»¥ç¯€çœç©ºé–“
            os.remove(audio_path)
            audio_path = wav_path
            
        # ä½¿ç”¨ Whisper é€²è¡ŒèªéŸ³è½‰æ–‡å­—
        print("- åŸ·è¡ŒèªéŸ³è½‰æ–‡å­—...")
        asr_result = self.whisper_model.transcribe(
            audio_path, 
            word_timestamps=True,  # å•Ÿç”¨å­—è©æ™‚é–“æˆ³è¨˜
            verbose=False
        )
        
        # ä½¿ç”¨ Pyannote é€²è¡Œèªªè©±äººåˆ†é›¢
        print("- åŸ·è¡Œèªªè©±äººåˆ†é›¢...")
        diarization = self.diarization_pipeline(audio_path)
        
        # æ•´åˆçµæœ
        print("- æ•´åˆçµæœ...")
        segments = []
        transcript_full = ""
        
        # è£½ä½œæ ¼å¼åŒ–çš„è¼¸å‡º
        for i, segment in enumerate(asr_result["segments"]):
            # æ‰¾å‡ºæ­¤æ®µè½çš„ä¸»è¦èªªè©±äºº
            segment_start = segment["start"]
            segment_end = segment["end"]
            text = segment["text"].strip()
            
            # å¾èªªè©±äººåˆ†é›¢çµæœä¸­æ‰¾å‡ºè¦†è“‹æ­¤æ®µè½æ™‚é–“æœ€å¤šçš„èªªè©±äºº
            speakers = {}
            for turn, _, speaker in diarization.itertracks(yield_label=True):
                # è¨ˆç®—é‡ç–Šæ™‚é–“
                overlap_start = max(segment_start, turn.start)
                overlap_end = min(segment_end, turn.end)
                
                if overlap_end > overlap_start:  # æœ‰é‡ç–Š
                    overlap_duration = overlap_end - overlap_start
                    if speaker in speakers:
                        speakers[speaker] += overlap_duration
                    else:
                        speakers[speaker] = overlap_duration
            
            # æ‰¾å‡ºä¸»è¦èªªè©±äºº (è¦†è“‹æ™‚é–“æœ€é•·)
            main_speaker = max(speakers.items(), key=lambda x: x[1])[0] if speakers else "æœªçŸ¥"
            
            segment_data = {
                "speaker": main_speaker,
                "start": segment_start,
                "end": segment_end,
                "text": text
            }
            
            segments.append(segment_data)
            transcript_full += f"[{main_speaker}] {segment_start:.1f}-{segment_end:.1f}: {text}\n"
        
        print(f"âœ… éŸ³æª”è™•ç†å®Œæˆï¼Œå…± {len(segments)} å€‹æ®µè½")
        return transcript_full, segments

    def generate_summary(self, transcript: str) -> Dict[str, str]:
        """ä½¿ç”¨ Gemini ç”Ÿæˆæ‘˜è¦å’Œå¾…è¾¦äº‹é …"""
        print("ğŸ”„ ç”Ÿæˆæ‘˜è¦èˆ‡å¾…è¾¦äº‹é …...")
        
        prompt = f"""
        ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„æœƒè­°è¨˜éŒ„å“¡ï¼Œä»¥ä¸‹æ˜¯ä¸€æ®µæœƒè­°çš„èªéŸ³è½‰æ–‡å­—è¨˜éŒ„ï¼Œè«‹å¹«æˆ‘ï¼š
        1. æ’°å¯«ä¸€æ®µä¸è¶…é300å­—çš„æ‘˜è¦
        2. åˆ—å‡ºä¸è¶…é5é …çš„é‡è¦å¾…è¾¦äº‹é … (To-Do)
        3. çµ¦é€™å€‹æœƒè­°ä¸€å€‹ç°¡çŸ­ä½†æè¿°æ€§å¼·çš„æ¨™é¡Œ
        
        èªéŸ³è¨˜éŒ„ï¼š
        {transcript}
        
        è«‹ä»¥ä¸‹åˆ—JSONæ ¼å¼å›è¦†ï¼š
        {{
            "title": "æœƒè­°æ¨™é¡Œ",
            "summary": "æœƒè­°æ‘˜è¦...",
            "todos": ["å¾…è¾¦äº‹é …1", "å¾…è¾¦äº‹é …2", ...]
        }}
        åªå›è¦†JSONï¼Œä¸è¦æœ‰å…¶ä»–æ–‡å­—ã€‚
        """
        
        try:
            model = genai.GenerativeModel('gemini-pro')
            response = model.generate_content(prompt)
            
            # è§£æ JSON å›æ‡‰
            summary_data = json.loads(response.text)
            print("âœ… æ‘˜è¦ç”Ÿæˆå®Œæˆ")
            return summary_data
        except Exception as e:
            print(f"âŒ æ‘˜è¦ç”Ÿæˆå¤±æ•—: {str(e)}")
            # è‹¥å¤±æ•—ï¼Œè¿”å›åŸºæœ¬è³‡æ–™
            return {
                "title": "æœƒè­°è¨˜éŒ„",
                "summary": "ç„¡æ³•ç”Ÿæˆæ‘˜è¦ï¼Œè«‹æŸ¥çœ‹åŸå§‹è¨˜éŒ„ã€‚",
                "todos": ["æª¢é–±æœƒè­°è¨˜éŒ„ä¸¦æ‰‹å‹•æ•´ç†é‡é»"]
            }

    def create_notion_page(self, title: str, summary: str, todos: List[str], transcript: str, segments: List[Dict[str, Any]]) -> str:
        """å»ºç«‹ Notion é é¢"""
        print("ğŸ”„ å»ºç«‹ Notion é é¢...")
        
        notion_token = os.getenv("NOTION_TOKEN")
        database_id = os.getenv("NOTION_DATABASE_ID")
        
        if not notion_token or not database_id:
            raise ValueError("ç¼ºå°‘ Notion API è¨­å®š")
            
        # è£½ä½œ Notion å€å¡Šå…§å®¹
        blocks = []
        
        # æ–°å¢æ‘˜è¦å€å¡Š
        blocks.append({
            "object": "block",
            "type": "heading_2",
            "heading_2": {
                "rich_text": [{"type": "text", "text": {"content": "æ‘˜è¦"}}]
            }
        })
        blocks.append({
            "object": "block",
            "type": "paragraph",
            "paragraph": {
                "rich_text": [{"type": "text", "text": {"content": summary}}]
            }
        })
        
        # æ–°å¢å¾…è¾¦äº‹é …å€å¡Š
        blocks.append({
            "object": "block",
            "type": "heading_2",
            "heading_2": {
                "rich_text": [{"type": "text", "text": {"content": "å¾…è¾¦äº‹é …"}}]
            }
        })
        
        for todo in todos:
            blocks.append({
                "object": "block",
                "type": "to_do",
                "to_do": {
                    "rich_text": [{"type": "text", "text": {"content": todo}}],
                    "checked": False
                }
            })
        
        # æ–°å¢å®Œæ•´è¨˜éŒ„å€å¡Š
        blocks.append({
            "object": "block",
            "type": "heading_2",
            "heading_2": {
                "rich_text": [{"type": "text", "text": {"content": "å®Œæ•´è¨˜éŒ„"}}]
            }
        })
        
        blocks.append({
            "object": "block",
            "type": "paragraph",
            "paragraph": {
                "rich_text": [{"type": "text", "text": {"content": "ä»¥ä¸‹æ˜¯æœƒè­°çš„å®Œæ•´è½‰éŒ„å…§å®¹ï¼š"}}]
            }
        })
        
        # æ¯å€‹æ®µè½ä½œç‚ºå–®ç¨çš„æ®µè½å€å¡Š
        for segment in segments:
            speaker = segment["speaker"]
            start_time = f"{segment['start']:.1f}"
            end_time = f"{segment['end']:.1f}"
            text = segment["text"]
            
            content = f"[{speaker}] {start_time}-{end_time}: {text}"
            
            blocks.append({
                "object": "block",
                "type": "paragraph",
                "paragraph": {
                    "rich_text": [{"type": "text", "text": {"content": content}}]
                }
            })
        
        # çµ„åˆ API è«‹æ±‚
        headers = {
            "Authorization": f"Bearer {notion_token}",
            "Content-Type": "application/json",
            "Notion-Version": "2022-06-28"
        }
        
        # è¨­å®šé é¢å…§å®¹
        current_date = datetime.now().strftime("%Y-%m-%d")
        data = {
            "parent": {"database_id": database_id},
            "properties": {
                "title": {
                    "title": [{"text": {"content": f"{title} ({current_date})"}}]
                }
            },
            "children": blocks
        }
        
        # ç™¼é€è«‹æ±‚
        try:
            response = requests.post(
                "https://api.notion.com/v1/pages",
                headers=headers,
                json=data
            )
            response.raise_for_status()
            result = response.json()
            page_id = result["id"]
            print(f"âœ… Notion é é¢å»ºç«‹æˆåŠŸ (ID: {page_id})")
            return page_id
        except Exception as e:
            print(f"âŒ Notion é é¢å»ºç«‹å¤±æ•—: {str(e)}")
            if hasattr(e, 'response') and e.response:
                print(f"éŸ¿æ‡‰å…§å®¹: {e.response.text}")
            raise

    def process_file(self, file_id: str) -> Dict[str, Any]:
        """è™•ç†å®Œæ•´æµç¨‹"""
        temp_dir = None
        
        try:
            # ä¸‹è¼‰æª”æ¡ˆ
            audio_path = self.download_from_drive(file_id)
            temp_dir = os.path.dirname(audio_path)
            
            # è™•ç†éŸ³æª”
            transcript, segments = self.process_audio(audio_path)
            
            # ç”Ÿæˆæ‘˜è¦
            summary_data = self.generate_summary(transcript)
            title = summary_data["title"]
            summary = summary_data["summary"]
            todos = summary_data["todos"]
            
            # ä¸Šå‚³åˆ° Notion
            page_id = self.create_notion_page(title, summary, todos, transcript, segments)
            
            # å›å‚³çµæœ
            return {
                "success": True,
                "notion_page_id": page_id,
                "title": title,
                "summary": summary,
                "todos": todos
            }
        
        finally:
            # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
            if temp_dir and os.path.exists(temp_dir):
                shutil.rmtree(temp_dir)

# å»ºç«‹å–®ä¸€ AudioProcessor å¯¦ä¾‹
processor = AudioProcessor()

@app.route('/health', methods=['GET'])
def health_check():
    """å¥åº·æª¢æŸ¥ç«¯é»"""
    return jsonify({"status": "healthy", "timestamp": datetime.now().isoformat()})

@app.route('/process', methods=['POST'])
def process_audio_endpoint():
    """è™•ç†éŸ³æª”çš„ API ç«¯é»"""
    try:
        # é©—è­‰è«‹æ±‚
        data = request.json
        
        if not data:
            return jsonify({"error": "ç„¡æ•ˆçš„è«‹æ±‚å…§å®¹"}), 400
        
        file_id = data.get('file_id')
        if not file_id:
            return jsonify({"error": "ç¼ºå°‘ file_id åƒæ•¸"}), 400
            
        # è™•ç†æª”æ¡ˆ
        result = processor.process_file(file_id)
        
        return jsonify(result)
        
    except Exception as e:
        print(f"API éŒ¯èª¤: {str(e)}")
        return jsonify({"error": str(e)}), 500

if __name__ == "__main__":
    # è¨­å®š Flask ä¼ºæœå™¨
    port = int(os.getenv("PORT", 5000))
    debug = os.getenv("FLASK_DEBUG", "false").lower() == "true"
    
    print(f"ğŸš€ å•Ÿå‹•ä¼ºæœå™¨æ–¼ port {port}...")
    app.run(host='0.0.0.0', port=port, debug=debug)
